---
title: "eyethinkphysiosync-vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{eyethinkphysiosync-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  out.width = "90%",
  fig.width = 6, 
  fig.height = 4,
  comment = "#>"
)
```

This is a toolbox for processing and analysing data from emotibit sensors. It will collate the physio data, re-running heart rate analyses with heart py, if required. It will then associate the data with logs, observational data, or output from a gorilla experiment, labeling the stimuli and attaching behavioural data. Finally, it contains tools for cross recurrence quantification analysis. It uses the eyethinkdata package, which will be installed if you don't have it.

Here's how to get the latest version (always recommended as there's a fair bit of development going on)

```{r eval=FALSE}
devtools::install_github("dcr-eyethink/eyethinkphysiosync")
```

```{r setup}
library(eyethinkphysiosync)
```

There are three main stages to this process: processing the raw emotibit data, trimming and integrating the data with a record of participants' experiences and behaviour, and then optionally running a cross recurrence analysis. In each case, there are single wrapper functions to achieve each of these in one command, but in this vignette I'll walk through the steps to show you the process. We will be processing data from a little experiment in which three participants watched 60 second advert and a 2 minute clip of a drama show.

### Emotibit pre-processing

The pre-processes is detailed here (). It's in a separate document because those processes require some additional software and python code to be installed. Assuming that you've done that step, or another lab member has done it for you, you can now compile all the data that's been pre-processed.  This function goes through all the emotibit data folders and compiles the data for the DVs that are named. It saves the data out to a file, emotibit_data_comb.csv, and returns it as a datatable

```{r}
processed_emotibit_data <- emotibit_compile(edv = c("HR","EA","ACC"),datafolder = "emotibit_data")
```
## Behavioural data

Now we can gather the behavioural data so we know what the participants were doing and seeing, and importantly, when. We want this trial data in the form of a data.table, typically called td, that has one row per person, per stimulus that they saw. This could be one of many 30 sec ads a person sees, or a 2 hour movie that each person sees once. 

### Format of trial data and participant data

Here's an example of the minimal information that we need in the trial data

```{r}
fread("eg_td.csv")
```

The first 4 columns here are required for the processes we will carry out below:
**pid** the paritcipant ID
**eid** the name of the sensor that the participant wore
**starttime** The UTC time code (https://www.unixtimestamp.com) when the stimulus started
**stoptime** end time of the stimulus

In addition you need one or more columns to pick out a unique trial or stimulus event (something that each participant only sees once). This could be the stimulus name, for example. Later we will be carrying out a cross recurrence analysis on all participants who experienced this same event, and this is how we will identify them.

Typically, I use more than one column, so that I can include information to identify types of trial or conditions. By convention, I use category, condition, item and stim columns, as we see here. But whatever is there will be populated throughout the data we generate. You can also include here any behavioural information about response to the stimuli, such as rating ro memory tasks. This data can be entered by hand into a spreadsheet, or taken from a experiment log, or derived from gorilla data.

### Processing gorilla standardised task

Many of the experiments run in the eyethink lab use a standardized task called snappily *AV block multiple stim types*. There are functions to automatically process data from the various versions of this task to generate summary data.

```{r echo=F}
processed_gorilla <- gorilla_physio_presentation(datafolder = "gorilla_data")
```

There are 2 outputs here. pd is the participant data, and looks like this for our toy experiment

```{r}
processed_gorilla$pd
```

And the trial data

```{r}
processed_gorilla$td
```

As well as the important trial start and stop times, we have the participants responses on the various rating tasks after each stimuli. We can now match up this trial information with the physiological data

### Linking physio and behavioural

The function that joins together the behavioural and emotibit data is called physio_merge(). It can take a while as there is a lot of processing. Before doing so, it's a good idea to run it with stop_at_plotcheck = T. This gives you a graphical representation of where you have emotibit and where you have gorilla data. Time is on the x axis, with days in different panels, and the different emotibit sensors are arrayed on the y axis. The emotibit sensor ids are read off from the SD cards for the emotibit data, and entered by the participant in the gorilla data. 

```{r}
physio_merge(processed_emotibit_data ,processed_gorilla,stop_at_plotcheck = T )
```

The black lines are where you have gorilla data (with the pids written nearby), and the red lines are the period for which you have physiological data. In a perfect world, all the red lines would appear over the black bars. But you may get times where the red lines don't fully cover the black areas, where the sensor battery gave out for example, or someone forgot to start recording. Another error that can occur is that the red lines will systematical be an hour off of the black bars in every case. This suggests that there has been some problem with the time zones. The emotibit chips don't handle British daylight savings very well. To correct for this, re run emotibit_compile() with hour_adjust = 1 or -1.

A further thing is look out for are times in which you have a black bar and a red line at the same time, but they aren't in top of each other. That has occurred at the top of this plot above. A reasonable explanation is that the participant has entered the eid incorrectly. Here they appear to have mistake the red case for an orange (to be fair, it is an orangey-red). Other typical mistakes are putting a 9 for a 6, for example. It's a good idea to confirm these errors by looking in the experiment log, where they experimenter should have noted the eid as well as a back up. 

There's a function to handle those corrections quickly. You just give it a data.table of pids and their correct eids, and it will go through your pd, td and any other data passed in a list to make correction. Then we can rerun the merging process and store it.

```{r }
processed_gorilla <- gorilla_eid_corrections(processed_gorilla, corrections=data.table(pid=c(10370290),eid=c("red4")))
data <- physio_merge(processed_emotibit_data ,processed_gorilla)
```

The physio_merge function spits out the plot to check your data alignment, as before, and also a plot of the eda data per person and emotibit sensor. There is a threshold (20 by default, shown as a line on the plot) such that if the mean EDA reading for someone is below that, we set filter=0 and they get excluded. Also we exclude people where the range of EDA values is small (default <0.03). In there cases that's either someone who is very sweaty or not at all sweaty, or a misplaced sensor. We also set filter=0 for individual measurements that are outside of thresholds (defaults <.01 & >25). In the trial data, td, we summarize how many measurements were excluded from each trial (you might want to throw out trials with less than a certain % of valid meaurements), and the average of those values for each person is reported as % in the plot. 

The main output of this function are the set of data.tables that give you the emotitbit measurements moment by moment (ed), the trial data (td) where those are summarized over trials, the participant data (pd) summarized over people and the stimuli data (sd) summarized over stimuli items.

You can look at the tiemcourse by plotting data$ed: 

```{r echo=F}
ggplot(data=data$ed,aes(x=tt,y=norm,colour=item))+geom_smooth()
```

However, using geom_smooth() sometimes results in too much smoothing. As an alternative for plotting, physio_merge() also outputs data$dm, which has each dv averaged over all participants in 1 second time bins, with the metrics of raw and morn scores. This can be plotted with geom_line()

```{r}
ggplot(data=data$dm[metric=="norm" & edv=="EA"],aes(x=t,y=y,colour=item))+geom_line()+theme_bw()
```

The whole data list of different data types can be saved out into separate .csv files with one command. It will put them in a folder called 'processed' by default, or you can specify a different name

```{r}
saveout_datalist(data)
```

If you are just interested in the behaviour and the physiological response of individuals, you can stop here. Or, in the next step, we take the ed data and calculate the physiological synchrony between these signals using cross recurrence analysis.

## Cross recurrence analysis

In this toolbox we use Dale and Coco's (21014) [CRQA methods paper and R toolbox](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2014.00510/full). This package adds a set of function that basically iterate the crqa() function over lots of trials and pairs of dyads. 
Here we have run the crqa_trials() function over our data of 3 participants watching two trials. We've turned on options to draw the pairs of time series and the cross recurrence plots for each pair of heart rate time series.

```{r echo=F}
   hr_crqa <-   crqa_trials(data=data,radius=.6,delay=2,embed=4,mindiagline=6,normalize=T,
                            edvs= list("HR"),drawplot=T,plot_ts=T)
```

The function returns crqa stats on every pairwise comparison for every trial.

```{r}
hr_crqa
```
Typically, we also want these pairwise comparisons data aggregated over trials, conditions or stimuli items. There is a wrapper function crqq_full() that will do this step too. Also, above we specified various crqa parameters like embedding and delay. From lots of experiences, we have a set of standard values that we use by default. The crqq_full() function runs a set of specified analyses using these defaults and returns the full rqa table, and updates our data list with averages over trials, people and stimuli items. By default it will run crqas for HR, EA and a multidemensional HR.EA combination, and windowed analyses. But you can also specify a subset of these. Here I've just asked for EA and windowed EA which give us time course information, since those are the measures that we have found are the best indicators of engagement. 

```{r echo=F, message=FALSE}
data <- crqa_full(data=data,analyses = c("EA","EAwin"))
```

That probably took a matter of seconds, since we only have 3 people watching 2 stimuli. But since pairwise comparisons are at the heart of crqa, you'll find that processing time increases rapidly with increasing participant numbers and stimuli lengths. We now have all the pairwise comparisons stored in data\$r, we have windowed timecourse data in data\$rw, the trial information in data\$td has been updated with summary stats for each participant's trial, and we have averages for each stimuli item in data\$sd. We can now visualise these. 

### Visualising item and condition differences

The means for the trial can be plotted like any other DV such as accuracy or reaction time using data$td. Of course, with only 2 trial and three people these differences are meaningless here. 

```{r}
pirateye(data$td,dv="DET_EA",x_condition = "item", violin=F)
```

You could also look for correlations between their DET scores and their explicit ratings in the trial data, or between the item mean DET scores in data\$sd and some external measure of engagement or success (such as sales figures, youtube likes, etc). The exclorr() function in eyethinkdata package maybe of use here. 

Also data$dm, the data table of time binned means, has been updated with the crqa metrics. You can use that that as above to plot time course

```{r warning=FALSE}
ggplot(data=data$dm[metric=="DET" & edv=="EA"],aes(x=t,y=y,colour=item))+geom_line()+theme_bw()

```

There is also a built in plotter for timecourse data that will smooth the plot a little. You just specify the metric and the dv that you want. You can tell it what column to use to split the data in different lines. So to contrast the two items:

```{r warning=FALSE}
physio_timeplot(data,plotmetric="DET",plotdv = "EA",contrast="item")
```

Or you can select what data to show by passing a data.table to selection. This will be matched to all rows in the data 

```{r warning=FALSE}
timeplot <- physio_timeplot(data,plotmetric="DET",plotdv = "EA",selection = data.table(item="benz"))
timeplot
```

You can also make a composite movie, with an animated version of the plots added to the stimulus movie. For this to work you need to have installed the packages gganimate and av into R, and also downloaded the application ffmpeg from https://ffmpeg.org. You can pass the plot that you have made with physio_timeplot(), as above, or just pass it the variables that physio_timeplot() needs and it'll make a new one. So the command below will animate the plot above and composite it with the benz.mp4 video. 

```{r eval=FALSE}
physio_movie(timeplot = timeplot,stimfile = "stim/benz.mp4")
```
Here's what that would output if run:

<video width="600"  controls>
  <source src="benz_spark.mp4" type="video/mp4">
</video>





