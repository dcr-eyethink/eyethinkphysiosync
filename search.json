[{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/data_output-vignette.html","id":"pd-csv---participants","dir":"Articles","previous_headings":"","what":"pd.csv - participants","title":"data_output-vignette","text":"know individual participants (demographics, debriefing notes, manipulation checks) experimental session (date, time, experiment version, conditions). carried sort rating performance task end main experiment, data summary form. also data mean EDA (media) range used exclude anomalous EDA data, eg sensor wasn’t working well. key column pid = participant ID, ties data together.","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/data_output-vignette.html","id":"ed-csv---physiological-sample","dir":"Articles","previous_headings":"","what":"ed.csv - physiological sample","title":"data_output-vignette","text":"files one row per person, per physiological sample, per measurement experiment. Since , eg, 15 samples per second EDA measurements, can large files. time codes given column t universal time codes (utc) can convert R using online converter. useful tt, time seconds onset experimental trial. different physiological signals identified dv column (note EDA referred EA ), data given raw form, norm normalised/z-scored individual participant. also columns help identify trials (typically, category, condition, stim, item). filtering data set can used plot time course physiological signals course individual stimuli.","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/data_output-vignette.html","id":"td-csv---trials","dir":"Articles","previous_headings":"","what":"td.csv - trials","title":"data_output-vignette","text":"data set probably useful analysis inferential statistics, contains one row per participant, per trial stimulus presented. well information identifying trial (category, condition, stim, item) behavioural data captured gorilla post presentation, ratings stimuli. behavioural test end experiment particular item (eg memory test), data summarised reported . summary physiological data derived ed.csv, mean range heart rate (eg raw_mean_HR), raw norm format. finally, summary statistics cross recurrence analysis calculated averaging rows r.csv. Typically analyses, look DET_EA, determinism EDA signal, signal pf physiological synchrony find strongest link engagement. Note may see NAs columns people - wil cases sensor failed got bad signal.","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/data_output-vignette.html","id":"sd-csv---stimuli","dir":"Articles","previous_headings":"","what":"sd.csv - stimuli","title":"data_output-vignette","text":"file derived others , summarises data produce means individual items stimuli can compared external data. example, rank movie trailers least engaging, try correlate global box office takings.","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/data_output-vignette.html","id":"r-csv---dyads-of-trials","dir":"Articles","previous_headings":"","what":"r.csv - dyads of trials","title":"data_output-vignette","text":"output cross recurrence quantification analysis (CRQA). analysis works calculating recurrence pairs time series, call dyads. us, times series physiological signals two people looking stimulus. every trial, one row every dyad participants saw , physiological measures (given dv column). standard information identify trial, well identify two participants (pinfo1 pinfo2). Usually, look recurrence everyone saw stimulus condition, sometimes might interested contrasting sub groups based upon people dyads (example, men vs women). sgroup tell two people dyad ingroup (eg say women men) groups (eg one man one woman), pgroup tell , -groups, groups two people member . get cross recurrence values particular row td.csv (say participant Joe looking stimulus ) average across every row participant Joe one two people dyad, looking . , interested DET measure .","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/data_output-vignette.html","id":"rw-csv---recurrence-of-dyads-per-second","dir":"Articles","previous_headings":"","what":"rw.csv - recurrence of dyads per second","title":"data_output-vignette","text":"r.csv , trial split chunks time (typically 1 second), can look time course recurrence values.","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/eyethinkphysiosync-vignette.html","id":"emotibit-pre-processing","dir":"Articles","previous_headings":"","what":"Emotibit pre-processing","title":"eyethinkphysiosync-vignette","text":"pre-processes detailed github. ’s separate document processes require additional software python code installed. Assuming ’ve done step, another lab member done , can now compile data ’s pre-processed. function goes emotibit data folders compiles data DVs named. saves data file, emotibit_data_comb.csv, returns datatable","code":"processed_emotibit_data <- emotibit_compile(edv = c(\"HR\",\"EA\",\"ACC\"),datafolder = \"emotibit_data\") #>  #> Reading  blue8_2024-02-13_11-37-17    HR  EA  ACC #> Reading  green6_2024-02-13_11-32-54   HR  EA  ACC #> Reading  red4_2024-02-13_11-27-08     HR  EA  ACC"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/eyethinkphysiosync-vignette.html","id":"behavioural-data","dir":"Articles","previous_headings":"","what":"Behavioural data","title":"eyethinkphysiosync-vignette","text":"Now can gather behavioural data know participants seeing, importantly, . want trial data form data.table, typically called td, one row per person, per stimulus saw. one many 30 sec ads person sees, 2 hour movie person sees .","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/eyethinkphysiosync-vignette.html","id":"format-of-trial-data-and-participant-data","dir":"Articles","previous_headings":"Behavioural data","what":"Format of trial data and participant data","title":"eyethinkphysiosync-vignette","text":"’s example minimal information need trial data first 4 columns required processes carry : pid paritcipant ID eid name sensor participant wore starttime UTC time code (https://www.unixtimestamp.com) stimulus started stoptime end time stimulus addition need one columns pick unique trial stimulus event (something participant sees ). stimulus name, example. Later carrying cross recurrence analysis participants experienced event, identify . Typically, use one column, can include information identify types trial conditions. convention, use category, condition, item stim columns, see . whatever populated throughout data generate. can also include behavioural information response stimuli, rating ro memory tasks. data can entered hand spreadsheet, taken experiment log, derived gorilla data.","code":"fread(\"eg_td.csv\") #>        pid     eid  starttime   stoptime category condition    item    stim #>      <int>  <char>      <int>      <int>   <char>    <char>  <char>  <char> #> 1: 9848500 orange5 1701171020 1701171240 politics       Yes yes_vid Yes.mp4 #> 2: 9848500 orange5 1701171269 1701171429 politics       Yes  no_vid  No.mp4 #> 3: 9848771   blue4 1701173489 1701173709 politics       Yes yes_vid Yes.mp4 #> 4: 9848771   blue4 1701173723 1701173883 politics       Yes  no_vid  No.mp4 #> 5: 9848965  green6 1701175506 1701175726 politics        No yes_vid Yes.mp4 #> 6: 9848965  green6 1701175747 1701175907 politics        No  no_vid  No.mp4"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/eyethinkphysiosync-vignette.html","id":"processing-gorilla-standardised-task","dir":"Articles","previous_headings":"Behavioural data","what":"Processing gorilla standardised task","title":"eyethinkphysiosync-vignette","text":"Many experiments run eyethink lab use standardized task called snappily AV block multiple stim types. functions automatically process data various versions task generate summary data. 2 outputs . pd participant data, looks like toy experiment trial data well important trial start stop times, participants responses various rating tasks stimuli. can now match trial information physiological data","code":"processed_gorilla$pd #> Key: <pid> #>         pid     eid        exp_begin exp_ver             exp_end   age    sex #>      <fctr>  <fctr>           <char>   <int>              <char> <num> <char> #> 1: 10370290 orange4 13/02/2024 11:27       3 13/02/2024 11:31:27    48   male #> 2: 10370446  green6 13/02/2024 11:32       3 13/02/2024 11:36:37    46 female #> 3: 10370528   blue8 13/02/2024 11:37       3 13/02/2024 11:41:26    50   male processed_gorilla$td #> Key: <pid, stim, condition, category, item> #>         pid     eid        exp_begin exp_ver             exp_end   age    sex #>      <fctr>  <fctr>           <char>   <int>              <char> <num> <char> #> 1: 10370290 orange4 13/02/2024 11:27       3 13/02/2024 11:31:27    48   male #> 2: 10370290 orange4 13/02/2024 11:27       3 13/02/2024 11:31:27    48   male #> 3: 10370446  green6 13/02/2024 11:32       3 13/02/2024 11:36:37    46 female #> 4: 10370446  green6 13/02/2024 11:32       3 13/02/2024 11:36:37    46 female #> 5: 10370528   blue8 13/02/2024 11:37       3 13/02/2024 11:41:26    50   male #> 6: 10370528   blue8 13/02/2024 11:37       3 13/02/2024 11:41:26    50   male #>           stim condition        category   item start_time  stop_time watched #>         <fctr>    <fctr>          <fctr> <fctr>      <num>      <num>   <num> #> 1: LATE_MB.mp4       end narrative_order   benz 1707823683 1707823742 58.7429 #> 2:   pizza.mp4       man         cluster  pizza 1707823778 1707823873 94.2234 #> 3: LATE_MB.mp4       end narrative_order   benz 1707823998 1707824057 58.7333 #> 4:   pizza.mp4       man         cluster  pizza 1707824092 1707824186 94.2228 #> 5: LATE_MB.mp4       end narrative_order   benz 1707824276 1707824340 63.9060 #> 6:   pizza.mp4       man         cluster  pizza 1707824380 1707824474 94.4520 #>    cluster.empathy.empathyslider1 cluster.empathy.empathyslider2 #>                             <num>                          <num> #> 1:                             NA                             NA #> 2:                             31                             66 #> 3:                             NA                             NA #> 4:                             78                             26 #> 5:                             NA                             NA #> 6:                             15                             85 #>    cluster.empathy.rightslider cluster.familiarity.slider1 #>                          <num>                       <num> #> 1:                          NA                          NA #> 2:                          80                          12 #> 3:                          NA                          NA #> 4:                          25                          75 #> 5:                          NA                          NA #> 6:                          75                          25 #>    cluster.familiarity.slider2 narrative.familiarity.scenefam #>                          <num>                          <num> #> 1:                          NA                              0 #> 2:                          51                             NA #> 3:                          NA                              1 #> 4:                          63                             NA #> 5:                          NA                              0 #> 6:                          41                             NA #>    narrative.familiarity.showfam narrative.likeability.emotion #>                            <num>                         <num> #> 1:                            61                            35 #> 2:                            NA                            NA #> 3:                            75                            67 #> 4:                            NA                            NA #> 5:                            75                            29 #> 6:                            NA                            NA #>    narrative.likeability.like narrative.likeability.shop #>                         <num>                      <num> #> 1:                         39                         35 #> 2:                         NA                         NA #> 3:                         69                         52 #> 4:                         NA                         NA #> 5:                         43                         26 #> 6:                         NA                         NA"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/eyethinkphysiosync-vignette.html","id":"linking-physio-and-behavioural","dir":"Articles","previous_headings":"Behavioural data","what":"Linking physio and behavioural","title":"eyethinkphysiosync-vignette","text":"function joins together behavioural emotibit data called physio_merge(). can take lot processing. , ’s good idea run stop_at_plotcheck = T. gives graphical representation emotibit gorilla data. Time x axis, days different panels, different emotibit sensors arrayed y axis. emotibit sensor ids read SD cards emotibit data, entered participant gorilla data.  black lines gorilla data (pids written nearby), red lines period physiological data. perfect world, red lines appear black bars. may get times red lines don’t fully cover black areas, sensor battery gave example, someone forgot start recording. Another error can occur red lines systematical hour black bars every case. suggests problem time zones. emotibit chips don’t handle British daylight savings well. correct , re run emotibit_compile() hour_adjust = 1 -1. thing look times black bar red line time, aren’t top . occurred top plot . reasonable explanation participant entered eid incorrectly. appear mistake red case orange (fair, orangey-red). typical mistakes putting 9 6, example. ’s good idea confirm errors looking experiment log, experimenter noted eid well back . ’s function handle corrections quickly. just give data.table pids correct eids, go pd, td data passed list make correction. can rerun merging process store .  physio_merge function spits plot check data alignment, , also plot eda data per person emotibit sensor. threshold (20 default, shown line plot) mean EDA reading someone , set filter=0 get excluded. Also exclude people range EDA values small (default <0.03). cases ’s either someone sweaty sweaty, misplaced sensor. also set filter=0 individual measurements outside thresholds (defaults <.01 & >25). trial data, td, summarize many measurements excluded trial (might want throw trials less certain % valid meaurements), average values person reported % plot. main output function set data.tables give emotitbit measurements moment moment (ed), trial data (td) summarized trials, participant data (pd) summarized people stimuli data (sd) summarized stimuli items. can look tiemcourse plotting data$ed:  However, using geom_smooth() sometimes results much smoothing. alternative plotting, physio_merge() also outputs data$dm, dv averaged participants 1 second time bins, metrics raw morn scores. can plotted geom_line()  whole data list different data types can saved separate .csv files one command. put folder called ‘processed’ default, can specify different name just interested behaviour physiological response individuals, can stop . , next step, take ed data calculate physiological synchrony signals using cross recurrence analysis.","code":"physio_merge(processed_emotibit_data ,processed_gorilla,stop_at_plotcheck = T ) processed_gorilla <- gorilla_eid_corrections(processed_gorilla, corrections=data.table(pid=c(10370290),eid=c(\"red4\"))) #> These cols were repeated in datatable 2 and used to replace earlier ones #> [1] \"eid\" #> These cols were repeated in datatable 2 and used to replace earlier ones #> [1] \"eid\" data <- physio_merge(processed_emotibit_data ,processed_gorilla) #>   |                                                                              |                                                                      |   0%  |                                                                              |============                                                          |  17%  |                                                                              |=======================                                               |  33%  |                                                                              |===================================                                   |  50%  |                                                                              |===============================================                       |  67%  |                                                                              |==========================================================            |  83%  |                                                                              |======================================================================| 100% #> `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")' ggplot(data=data$dm[metric==\"norm\" & edv==\"EA\"],aes(x=t,y=y,colour=item))+geom_line()+theme_bw() saveout_datalist(data)"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/eyethinkphysiosync-vignette.html","id":"cross-recurrence-analysis","dir":"Articles","previous_headings":"","what":"Cross recurrence analysis","title":"eyethinkphysiosync-vignette","text":"toolbox use Dale Coco’s (21014) CRQA methods paper R toolbox. package adds set function basically iterate crqa() function lots trials pairs dyads. run crqa_trials() function data 3 participants watching two trials. ’ve turned option draw pairs time series pair heart rate time series.       function returns crqa stats every pairwise comparison every trial. Typically, also want pairwise comparisons data aggregated trials, conditions stimuli items. wrapper function crqq_full() step . Also, specified various crqa parameters like embedding delay. lots experiences, set standard values use default. crqq_full() function runs set specified analyses using defaults returns full rqa table, updates data list averages trials, people stimuli items. default run crqas HR, EA multidemensional HR.EA combination, windowed analyses. can also specify subset . ’ve just asked EA windowed EA give us time course information, since measures found best indicators engagement. probably took matter seconds, since 3 people watching 2 stimuli. since pairwise comparisons heart crqa, ’ll find processing time increases rapidly increasing participant numbers stimuli lengths. now pairwise comparisons stored data$r, windowed timecourse data data$rw, trial information data$td updated summary stats participant’s trial, averages stimuli item data$sd. can now visualise .","code":"#> HR  item:  narrative_order§end§benz§LATE_MB.mp4   progress 50 % #>   |                                                                              |                                                                      |   0%  |                                                                              |=======================                                               |  33% #> Warning: no DISPLAY variable so Tk is not available #>   |                                                                              |===============================================                       |  67% #>   |                                                                              |======================================================================| 100% #>  #> HR  item:  cluster§man§pizza§pizza.mp4   progress 100 % #>   |                                                                              |                                                                      |   0%  |                                                                              |=======================                                               |  33% #>   |                                                                              |===============================================                       |  67% #>   |                                                                              |======================================================================| 100% #>  #> That took me #>       user     system    elapsed  #> 0.01498333 0.00040000 0.01808333 hr_crqa #>           category condition   item        stim    edv #>             <char>    <char> <char>      <char> <char> #> 1: narrative_order       end   benz LATE_MB.mp4     HR #> 2: narrative_order       end   benz LATE_MB.mp4     HR #> 3: narrative_order       end   benz LATE_MB.mp4     HR #> 4:         cluster       man  pizza   pizza.mp4     HR #> 5:         cluster       man  pizza   pizza.mp4     HR #> 6:         cluster       man  pizza   pizza.mp4     HR #>                                     gid  dyad     pid1     pid2       RR #>                                  <fctr> <int>   <char>   <char>    <num> #> 1: narrative_order§end§benz§LATE_MB.mp4     1 10370290 10370446 21.44970 #> 2: narrative_order§end§benz§LATE_MB.mp4     2 10370290 10370528 23.74260 #> 3: narrative_order§end§benz§LATE_MB.mp4     3 10370446 10370528 21.81953 #> 4:          cluster§man§pizza§pizza.mp4     1 10370290 10370446 19.81768 #> 5:          cluster§man§pizza§pizza.mp4     2 10370290 10370528 21.27097 #> 6:          cluster§man§pizza§pizza.mp4     3 10370446 10370528 16.03911 #>         DET NRLINE  maxL         L     ENTR     rENTR      LAM       TT  catH #>       <num>  <num> <num>     <num>    <num>     <num>    <num>    <num> <num> #> 1: 63.44828     33    20 11.151515 2.282987 0.9187414 87.41379 7.242857    NA #> 2: 73.36449     49    24  9.612245 2.018567 0.8123311 97.19626 6.709677    NA #> 3: 55.25424     30    18 10.866667 2.118279 0.9199570 98.64407 6.000000    NA #> 4: 52.46667     92    16  8.554348 2.042916 0.8519621 89.66667 4.769504    NA #> 5: 70.99379    108    27 10.583333 2.551037 0.8379103 95.21739 5.656827    NA #> 6: 46.78748     61    21  9.311475 2.248248 0.8765273 94.06919 4.680328    NA #>                                             tid1 #>                                           <fctr> #> 1: 10370290-narrative_order-end-benz-LATE_MB.mp4 #> 2: 10370290-narrative_order-end-benz-LATE_MB.mp4 #> 3: 10370446-narrative_order-end-benz-LATE_MB.mp4 #> 4:          10370290-cluster-man-pizza-pizza.mp4 #> 5:          10370290-cluster-man-pizza-pizza.mp4 #> 6:          10370446-cluster-man-pizza-pizza.mp4 #>                                             tid2 #>                                           <fctr> #> 1: 10370446-narrative_order-end-benz-LATE_MB.mp4 #> 2: 10370528-narrative_order-end-benz-LATE_MB.mp4 #> 3: 10370528-narrative_order-end-benz-LATE_MB.mp4 #> 4:          10370446-cluster-man-pizza-pizza.mp4 #> 5:          10370528-cluster-man-pizza-pizza.mp4 #> 6:          10370528-cluster-man-pizza-pizza.mp4 #> EA  item:  narrative_order§benz§LATE_MB.mp4§end   progress 50 % #>   |                                                                              |                                                                      |   0%  |                                                                              |=======================                                               |  33%  |                                                                              |===============================================                       |  67%  |                                                                              |======================================================================| 100% #> EA  item:  cluster§pizza§pizza.mp4§man   progress 100 % #>   |                                                                              |                                                                      |   0%  |                                                                              |=======================                                               |  33%  |                                                                              |===============================================                       |  67%  |                                                                              |======================================================================| 100% #> That took me #>        user      system     elapsed  #> 0.001633333 0.000000000 0.001316667  #> Proportions where we have no RR data #>       edv    V1 #>    <char> <num> #> 1:     EA     0 #> Proportions where we have no DET data #>       edv    V1 #>    <char> <num> #> 1:     EA     0 #> EA  item:  narrative_order§benz§LATE_MB.mp4§end   progress 50 % #>   |                                                                              |                                                                      |   0%  |                                                                              |=======================                                               |  33%  |                                                                              |===============================================                       |  67%  |                                                                              |======================================================================| 100% #> EA  item:  cluster§pizza§pizza.mp4§man   progress 100 % #>   |                                                                              |                                                                      |   0%  |                                                                              |=======================                                               |  33%  |                                                                              |===============================================                       |  67%  |                                                                              |======================================================================| 100% #> That took me #>       user     system    elapsed  #> 0.01760000 0.00005000 0.01626667"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/articles/eyethinkphysiosync-vignette.html","id":"visualising-item-and-condition-differences","dir":"Articles","previous_headings":"Cross recurrence analysis","what":"Visualising item and condition differences","title":"eyethinkphysiosync-vignette","text":"means trial can plotted like DV accuracy reaction time using data$td. course, 2 trial three people differences meaningless .  also look correlations DET scores explicit ratings trial data, item mean DET scores data$sd external measure engagement success (sales figures, youtube likes, etc). exclorr() function eyethinkdata package maybe use . Also data$dm, data table time binned means, updated crqa metrics. can use plot time course  also built plotter timecourse data smooth plot little. just specify metric dv want. can tell column use split data different lines. contrast two items:  can select data show passing data.table selection. matched rows data  can also make composite movie, animated version plots added stimulus movie. work need installed packages gganimate av R, also downloaded application ffmpeg https://ffmpeg.org. can pass plot made physio_timeplot(), , just pass variables physio_timeplot() needs ’ll make new one. command animate plot composite benz.mp4 video. ’s output run:","code":"pirateye(data$td,dv=\"DET_EA\",x_condition = \"item\", violin=F) ggplot(data=data$dm[metric==\"DET\" & edv==\"EA\"],aes(x=t,y=y,colour=item))+geom_line()+theme_bw() physio_timeplot(data,plotmetric=\"DET\",plotdv = \"EA\",contrast=\"item\") timeplot <- physio_timeplot(data,plotmetric=\"DET\",plotdv = \"EA\",selection = data.table(item=\"benz\")) timeplot physio_movie(timeplot = timeplot,stimfile = \"stim/benz.mp4\")"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"DCR. Maintainer.","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"person, c) c= (2024). eyethinkphysiosync: Tools processing physiological data calculating synchrony. R package version 0.3.1, https://dcr-eyethink.github.io/eyethinkphysiosync/, https://github.com/dcr-eyethink/eyethinkphysiosync.","code":"@Manual{,   title = {eyethinkphysiosync: Tools for processing physiological data and calculating synchrony},   author = {{person} and comment = c)},   year = {2024},   note = {R package version 0.3.1, https://dcr-eyethink.github.io/eyethinkphysiosync/},   url = {https://github.com/dcr-eyethink/eyethinkphysiosync}, }"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/index.html","id":"readme-eyethink-physiological-synchrony","dir":"","previous_headings":"","what":"Tools for processing physiological data and calculating synchrony","title":"Tools for processing physiological data and calculating synchrony","text":"2024-01-23","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/index.html","id":"eyethink-physiological-data-and-synchrony-analysis","dir":"","previous_headings":"","what":"Eyethink: Physiological Data and Synchrony Analysis","title":"Tools for processing physiological data and calculating synchrony","text":"toolbox processing data emotibit sensors, labelling/linking behavioural data gorilla, running cross recurrence analysis. part eyethink toolbox requires eyethinkdata package. Use code install update github vignette walk using package functions. can access R can also read vignette online github website.","code":"devtools::install_github(\"dcr-eyethink/eyethinkphysiosync\") library(eyethinkphysiosync) vignette(\"eyethinkphysiosync_vignette\",package = \"eyethinkphysiosync\")"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/crqa_dyads.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorized rqa over a set of timeseries grouped by gid\nsingle or multidimensional\nfigures out all possible dyads in set\nand runs rqa on them — crqa_dyads","title":"Vectorized rqa over a set of timeseries grouped by gid\nsingle or multidimensional\nfigures out all possible dyads in set\nand runs rqa on them — crqa_dyads","text":"Vectorized rqa set timeseries grouped gid single multidimensional figures possible dyads set runs rqa ","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/crqa_dyads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vectorized rqa over a set of timeseries grouped by gid\nsingle or multidimensional\nfigures out all possible dyads in set\nand runs rqa on them — crqa_dyads","text":"","code":"crqa_dyads(gdata, opt, ...)"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/crqa_full.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs through a set of standardized rqa metrics, by running crqa_trials() for each — crqa_full","title":"Runs through a set of standardized rqa metrics, by running crqa_trials() for each — crqa_full","text":"Runs set standardized rqa metrics, running crqa_trials() ","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/crqa_full.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs through a set of standardized rqa metrics, by running crqa_trials() for each — crqa_full","text":"","code":"crqa_full(   data,   analyses = c(\"HR\", \"EA\", \"HR.EA\", \"HRwin\", \"EAwin\"),   condcols = c(\"category\", \"item\", \"stim\", \"condition\"),   easample = 15,   eawsize = 30,   eawstep = 10,   writecache = T,   pinfo = NULL,   ... )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/crqa_full.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs through a set of standardized rqa metrics, by running crqa_trials() for each — crqa_full","text":"data data list containing least ed, labelled emotibit data compiling merging functions analyses set CRQA analyses run condcols column names identify unique trials analysed together crqa. Null one trial per person","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/crqa_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Averages a table of pairwise comparisons over people (default), trials or conditions — crqa_means","title":"Averages a table of pairwise comparisons over people (default), trials or conditions — crqa_means","text":"Doubles table first, ie looks full square rather upper triangle, gets means rqa_vars average_over","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/crqa_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Averages a table of pairwise comparisons over people (default), trials or conditions — crqa_means","text":"","code":"crqa_means(   data,   average_over = \"pid1\",   rqa_vars = c(\"cor\", \"RR\", \"DET\", \"NRLINE\", \"maxL\", \"L\", \"ENTR\", \"rENTR\", \"LAM\", \"TT\") )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/crqa_trials.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs crqa, mdcrqa or mdrqa on pairs or groups — crqa_trials","title":"Runs crqa, mdcrqa or mdrqa on pairs or groups — crqa_trials","text":"group together items using condcols, people using pinfo","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/crqa_trials.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs crqa, mdcrqa or mdrqa on pairs or groups — crqa_trials","text":"","code":"crqa_trials(   data,   condcols = c(\"category\", \"condition\", \"item\", \"stim\"),   pinfo = NULL,   pid = \"pid\",   edvs = NULL,   opt = F,   dyads = T,   pseudo_dyads = F,   announce = F,   samplerate = 1,   ... )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/crqa_trials.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs crqa, mdcrqa or mdrqa on pairs or groups — crqa_trials","text":"data ed data list containing ed, labelled emotibit data compiling merging functions condcols column names identify unique trials analysed together crqa. Null one trial per person pinfo column person designator, group differences pid column name unique subject ID edvs list DVs crq process, can multidimensional. null dyads cross recurrence dyads T, F multidimensional analysis","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_compile.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs through data folder, collating named emotibit DVs (edv) into one file — emotibit_compile","title":"Runs through data folder, collating named emotibit DVs (edv) into one file — emotibit_compile","text":"getting work, need process_bpm.py folder need create virtual environment python 3","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_compile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs through data folder, collating named emotibit DVs (edv) into one file — emotibit_compile","text":"","code":"emotibit_compile(   datafolder = NULL,   edv = c(\"EA\", \"HR\", \"ACC\"),   hour_adjust = 0,   minstart = \"2020-01-01 01:00:01 BST\",   fix_timestamp_from_file = T,   logging = T,   ... )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_compile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs through data folder, collating named emotibit DVs (edv) into one file — emotibit_compile","text":"datafolder folder raw .csv data .json files multiple sessions sensors, blank ask one system dialog edv emotibit time series data require. files listed session folders emotibit_data_XX.csv, XX dv name hour_adjust correction time zones / day light savings. minstart data time stamped point, going assume timestamps wrong fix_timestamp_from_file case minstart finds problem, try reconstruct start times filenames logging save emotibit_data_comb.csv disk output logs errors, plots sessions. FALSE just returns compiled data","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_getsessionfolders.html","id":null,"dir":"Reference","previous_headings":"","what":"given a datafolder filepath, or named directory in working directory, or nothing\nit returns a list of emotibit session folders — emotibit_getsessionfolders","title":"given a datafolder filepath, or named directory in working directory, or nothing\nit returns a list of emotibit session folders — emotibit_getsessionfolders","text":"given datafolder filepath, named directory working directory, nothing returns list emotibit session folders","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_getsessionfolders.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"given a datafolder filepath, or named directory in working directory, or nothing\nit returns a list of emotibit session folders — emotibit_getsessionfolders","text":"","code":"emotibit_getsessionfolders(datafolder)"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_heartpy.html","id":null,"dir":"Reference","previous_headings":"","what":"Run heartpy through data to regenerate heart rate — emotibit_heartpy","title":"Run heartpy through data to regenerate heart rate — emotibit_heartpy","text":"getting work, need process_bpm.py folder need create virtual environment python 3 folder, install heartpy. ran:   ###  python3 -m venv /Users/dcr/Dropbox/Rwork/python/hp   ###  source venv/bin/activate   ###  pip install heartpy","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_heartpy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run heartpy through data to regenerate heart rate — emotibit_heartpy","text":"","code":"emotibit_heartpy(   datafolder = NULL,   heartpy_reparse = F,   winsize = 8,   heartpy_location = \"/Users/dcr/Dropbox/Rwork/python/hp\" )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_heartpy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run heartpy through data to regenerate heart rate — emotibit_heartpy","text":"datafolder folder raw .csv data .json files multiple sessions sensors, blank ask one system dialog heartpy_reparse force re-parsing data winsize window calculating heart rate location emotibit parser file computer","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_parser.html","id":null,"dir":"Reference","previous_headings":"","what":"Run emotibit data through parser to make files for each sensor — emotibit_parser","title":"Run emotibit data through parser to make files for each sensor — emotibit_parser","text":"Run emotibit data parser make files sensor","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_parser.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run emotibit data through parser to make files for each sensor — emotibit_parser","text":"","code":"emotibit_parser(   datafolder = NULL,   reparse = F,       parser_location = \"/Applications/EmotiBitSoftware-macOS/EmotiBitDataParser.app/Contents/MacOS/EmotiBitDataParser\" )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_parser.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run emotibit data through parser to make files for each sensor — emotibit_parser","text":"datafolder folder raw .csv data .json files multiple sessions sensors, blank ask one system dialog reparse force re-parsing data location emotibit parser file computure","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_process.html","id":null,"dir":"Reference","previous_headings":"","what":"Organize, process and compiles emotibit raw data files and .json files — emotibit_process","title":"Organize, process and compiles emotibit raw data files and .json files — emotibit_process","text":"starts folder contains .csv .json data files emotibit SD cards, ends data parsed organised folders, compiled single data.table can pass","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Organize, process and compiles emotibit raw data files and .json files — emotibit_process","text":"","code":"emotibit_process(datafolder = NULL, ...)"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Organize, process and compiles emotibit raw data files and .json files — emotibit_process","text":"datafolder folder raw .csv data .json files multiple sessions sensors, blank ask one system dialog ... Arguments emotibit_session_folders, emotibit_parser, emotibit_heartpy, emotibit_compile","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_session_folders.html","id":null,"dir":"Reference","previous_headings":"","what":"Organize emotibit raw data files and .json files, into labelled session folders.\nWill default to using the eyethink lab key to translate the emotibit serial IDs into soemthing more friendly — emotibit_session_folders","title":"Organize emotibit raw data files and .json files, into labelled session folders.\nWill default to using the eyethink lab key to translate the emotibit serial IDs into soemthing more friendly — emotibit_session_folders","text":"Organize emotibit raw data files .json files, labelled session folders. default using eyethink lab key translate emotibit serial IDs soemthing friendly","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_session_folders.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Organize emotibit raw data files and .json files, into labelled session folders.\nWill default to using the eyethink lab key to translate the emotibit serial IDs into soemthing more friendly — emotibit_session_folders","text":"","code":"emotibit_session_folders(   datafolder = NULL,   overwrite = F,   sensor_id = \"eyethink\",   destination = \"emotibit_data\" )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_session_folders.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Organize emotibit raw data files and .json files, into labelled session folders.\nWill default to using the eyethink lab key to translate the emotibit serial IDs into soemthing more friendly — emotibit_session_folders","text":"datafolder folder raw .csv data .json files multiple sessions sensors, blank ask one system dialog overwrite skip folders already exist default, unless set T sensor_id key use: \"eyethink\", \"none\" name file headings eid serialid. blank find file, ask location destination name folder sorted files end . Set NULL overwriting","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/emotibit_session_folders.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Organize emotibit raw data files and .json files, into labelled session folders.\nWill default to using the eyethink lab key to translate the emotibit serial IDs into soemthing more friendly — emotibit_session_folders","text":"name (new) datafolder","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/eyethinkphysiosync-package.html","id":null,"dir":"Reference","previous_headings":"","what":"eyethinkphysiosync: Tools for processing physiological data and calculating synchrony — eyethinkphysiosync-package","title":"eyethinkphysiosync: Tools for processing physiological data and calculating synchrony — eyethinkphysiosync-package","text":"Proceses data emotibit sensors, labels behavioural data gorilla runs cross recurrence analysis","code":""},{"path":[]},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_eid_corrections.html","id":null,"dir":"Reference","previous_headings":"","what":"corrects eid from list of pid throughout data packet — gorilla_eid_corrections","title":"corrects eid from list of pid throughout data packet — gorilla_eid_corrections","text":"corrects eid list pid throughout data packet","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_eid_corrections.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"corrects eid from list of pid throughout data packet — gorilla_eid_corrections","text":"","code":"gorilla_eid_corrections(processed_gorilla, corrections)"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_emotibit_eid.html","id":null,"dir":"Reference","previous_headings":"","what":"Get ID from gorilla questionnaire — gorilla_emotibit_eid","title":"Get ID from gorilla questionnaire — gorilla_emotibit_eid","text":"Get ID gorilla questionnaire","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_emotibit_eid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get ID from gorilla questionnaire — gorilla_emotibit_eid","text":"","code":"gorilla_emotibit_eid(data = NULL, eidtask = \"Emotibit_ID\")"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_emotibit_eid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get ID from gorilla questionnaire — gorilla_emotibit_eid","text":"data compiled gorilla data","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_emotibit_eid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get ID from gorilla questionnaire — gorilla_emotibit_eid","text":"pid, eid, experiment start time experiment version","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_physio_presentation.html","id":null,"dir":"Reference","previous_headings":"","what":"Process gorilla data from task 'AV block multiple stim types' — gorilla_physio_presentation","title":"Process gorilla data from task 'AV block multiple stim types' — gorilla_physio_presentation","text":"Process gorilla data task 'AV block multiple stim types'","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_physio_presentation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process gorilla data from task 'AV block multiple stim types' — gorilla_physio_presentation","text":"","code":"gorilla_physio_presentation(   data = NULL,   datafolder = NULL,   taskname = \"AV block multiple stim types\",   condcols = c(\"stim\", \"condition\", \"category\", \"item\"),   qlist = \"demographics\",   stim_screen = \"stimuli\",   quantkey = NULL,   post_task = NULL,   post_task_link = \"item\",   ... )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_physio_presentation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process gorilla data from task 'AV block multiple stim types' — gorilla_physio_presentation","text":"data list imported data data_collator_gorilla() datafolder data supplied, looks folder collection gorilla downloads. NULL ask file location condcols names columns pick unique trial data stim_screen critical video stimuli identified rows Zone.Type \"content_video\"  Screen.Name gorilla list quantkey data.table Response (text likert button) r (number want assign)","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_physio_presentation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process gorilla data from task 'AV block multiple stim types' — gorilla_physio_presentation","text":"td (trial data) pd (participant data)","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_physio_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Process gorilla data from test phase of physiological sync experiment — gorilla_physio_test","title":"Process gorilla data from test phase of physiological sync experiment — gorilla_physio_test","text":"Process gorilla data test phase physiological sync experiment","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_physio_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process gorilla data from test phase of physiological sync experiment — gorilla_physio_test","text":"","code":"gorilla_physio_test(   data,   test_task = \"post_memory\",   post_task_link = c(\"item\"),   memory_id = c(\"item\"),   image_id = \"ad_image\",   frag_id = \"ad_fragment\",   set_id = \"ad_set\" )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_physio_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process gorilla data from test phase of physiological sync experiment — gorilla_physio_test","text":"data either task data already filtered post task, imported data list, filtered test_task test_task names post tasks analyse ","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/gorilla_physio_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process gorilla data from test phase of physiological sync experiment — gorilla_physio_test","text":"td (trial data) full post test data, one line per trial","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/physio_merge.html","id":null,"dir":"Reference","previous_headings":"","what":"Label physio data with trial info\nlabels the data stream with participant and condition info\nbased on eid and timestamp — physio_merge","title":"Label physio data with trial info\nlabels the data stream with participant and condition info\nbased on eid and timestamp — physio_merge","text":"Label physio data trial info labels data stream participant condition info based eid timestamp","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/physio_merge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Label physio data with trial info\nlabels the data stream with participant and condition info\nbased on eid and timestamp — physio_merge","text":"","code":"physio_merge(   processed_emotibit = NULL,   processed_gorilla = NULL,   td = NULL,   sinfo = NULL,   pd = NULL,   sd = NULL,   ed = NULL,   condcols = c(\"category\", \"condition\", \"item\", \"stim\"),   normlevel = 1,   pinfo = NULL,   gd = NULL,   baseline = FALSE,   hour_adjust = 0,   stop_at_plotcheck = F,   eda_check = list(mean = 20, range_min = 0.01, low = 0.03, high = 25) )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/physio_merge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Label physio data with trial info\nlabels the data stream with participant and condition info\nbased on eid and timestamp — physio_merge","text":"processed_emotibit output emotibit_process() eomotibit_compile() used processed_gorilla output gorilla_physio_presentation used td trial data, including pid, eid, cond(s), starttime stoptime, (processed_gorilla) pd participant data, (processed_gorilla) sd stimuli data, (processed_gorilla) ed physio data, post compilation, (processed_emotibit) condcols cols td pick unique trial. person just saw single event, set NULL normlevel defaults 1 zscoring per person. Set 2+ additional column condcols use pinfo name column participant data identifies social group baseline implemented yet. want z score using sd (F default) just baseline shift (T) hour_adjust nunmber hours shift physio data , case GMT problem eda_check set NULL wanted, otherwise list mean, range_min, lod high thresholds EDA filtering","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/physio_merge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Label physio data with trial info\nlabels the data stream with participant and condition info\nbased on eid and timestamp — physio_merge","text":"labeled ed, td, pd sd data summary stats","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/physio_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Animates a physio_timeplot, scales and adds to stimulus video into a composite movie — physio_movie","title":"Animates a physio_timeplot, scales and adds to stimulus video into a composite movie — physio_movie","text":"Animates physio_timeplot, scales adds stimulus video composite movie","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/physio_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Animates a physio_timeplot, scales and adds to stimulus video into a composite movie — physio_movie","text":"","code":"physio_movie(   timeplot = NULL,   stimfile = NULL,   outputfile = NULL,   fps = 30,   spwidth = 800,   spheight = 400,   ... )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/physio_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Animates a physio_timeplot, scales and adds to stimulus video into a composite movie — physio_movie","text":"timeplot plot function physio_timeplot, pass variables function make new one stimfile stimulus video - leave blank can select file OS outputfile name composite movie. blank, just use stim file name add _spark fps frame per second movie spwidth width sparkline movie - sitmulus movie scaled width composited spheight height sparkline movie ... Arguments passed physio_timeplot data data list physio_merge plotmetric metric data$dm plot, eg DET norm plotdv dv, eg HR EA selection datatable columns values want use select data plot smoother parameter loess smoothing. set 0 none plot_error give error smoothing","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/physio_timeplot.html","id":null,"dir":"Reference","previous_headings":"","what":"plots data from dm — physio_timeplot","title":"plots data from dm — physio_timeplot","text":"plots data dm","code":""},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/physio_timeplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plots data from dm — physio_timeplot","text":"","code":"physio_timeplot(   data,   plotmetric,   plotdv,   selection = NULL,   contrast = NULL,   smoother = 0.3,   plot_error = F,   title = NULL,   outp = \"analysis\",   h = 4,   w = 6 )"},{"path":"https://dcr-eyethink.github.io/eyethinkphysiosync/reference/physio_timeplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plots data from dm — physio_timeplot","text":"data data list physio_merge plotmetric metric data$dm plot, eg DET norm plotdv dv, eg HR EA selection datatable columns values want use select data plot smoother parameter loess smoothing. set 0 none plot_error give error smoothing","code":""}]
